# Emerging Technologies Project

Name: Matthew Sloyan
Student ID: G00348036

# Project statement
**Model:** Create, document, and train a model that recognises hand-written digits using the MNIST dataset. This should be done using the keras and jupyter Python.

**Application:** Create a web application that allows a user to draw a digit using their mouse or touchscreen device. The drawing should then be then be submitted for recognition to the model you have trained above. This should be done using the flask Python package.

# Platforms
Coded and tested on a Linux Ubuntu 18.04 LTS virtual machine using VMware.

# How to run
* First, clone the repository using the following command `git clone https://github.com/MatthewSloyan/4th-Year-MNIST-Image-Recognition-Web-Application.git` 
* Traverse using the command line to the folder you have cloned using the cd command.
* From the command line run the following command. `will be updated`

# User Guide
Below you’ll find a basic guide to the user interface, in the “How it works” section is a description of how this works in the code behind.

Will be updated.

# Project Plan
* Week 1 - Initial research and setup of project.
* Week 2 - Reading the MNIST datasets and displaying the results.
* Week 3 - Training the MNIST dataset using Jupyter.
* Week 4 - Development of Flask web application.	
* Week 5 - Testing of web application with model.
* Week 6 - Adding finishing touches, tidying up code, and adding extras.

# Research & Development Diary

#### Start of Semester to 06-11-19
Each week I watched the various videos posted on Moodle and read into more about each topic such as Collatz, simple linear regression, deep learning and Newton's method. I also researched online more about Jupyter notebooks to get a grasp of how they work as we hadn’t any experience with it. This has really helped me with this project and will be a valuable skill going forward in my career. 

#### Week of 06-11-19 to 13-11-19
To help with the project I researched more about the MNIST dataset with help from the sources on Moodle. From this I found out more about how it's compressed and the possible ways to read it. With help from the video on Moodle I began coding a basic C program that reads in the bytes for the uncompressed training dataset of images. The results correlated with the sample data on the MNIST website, so it was a success. I then went on to code a similar program in Python from what I had learn which allowed me to display the results visually using matplotlib. As it's been read in correctly, I can move onto training the dataset using Keras.
